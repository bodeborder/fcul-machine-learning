{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, max_error, mean_absolute_error\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import Counter\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe from the dataset\n",
    "df = pd.read_csv(\"HA1-DatasetScaled.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critical_temp                  1.000000\n",
      "wtd_std_ThermalConductivity    0.723885\n",
      "range_ThermalConductivity      0.690854\n",
      "std_ThermalConductivity        0.659737\n",
      "range_atomic_radius            0.652120\n",
      "                                 ...   \n",
      "gmean_Density                 -0.539644\n",
      "gmean_Valence                 -0.574771\n",
      "mean_Valence                  -0.601432\n",
      "wtd_gmean_Valence             -0.618376\n",
      "wtd_mean_Valence              -0.634921\n",
      "Name: critical_temp, Length: 82, dtype: float64\n",
      "(21174, 81)\n",
      "(21174,)\n"
     ]
    }
   ],
   "source": [
    "#defining the X and y for the train test split\n",
    "X = df.values[:,:81]\n",
    "y = df.values[:,81] #critical_temp is the last column\n",
    "\n",
    "#creates a matrix of correlations\n",
    "corr_matrix = df.corr() \n",
    "#how much each attribute correlates with the critical_temp target variable value, the lower the value the least relevant the feature is\n",
    "print(corr_matrix[\"critical_temp\"].sort_values(ascending=False))\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#Creating an independent Validation Set (IVS)\n",
    "X_TRAIN, X_IVS, y_TRAIN, y_IVS = train_test_split(X, y, test_size=0.25, random_state=26)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the range of values of the max_depth hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 7, 10, 13, 16, 19, 22, 25, 28]\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter max depth\n",
    "\n",
    "max_depth_values = [] #to alter hyperparameter max_depth\n",
    "\n",
    "for i in range(1,30,3):\n",
    "    max_depth_values.append(i)\n",
    "       \n",
    "print(max_depth_values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor with hyperparameter max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor with max_depth = 1\n",
      "\n",
      "The RVE is:  0.5309561096889127\n",
      "The rmse is:  23.408991355354622\n",
      "The Correlation Score is is: 0.7287 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  175.52505396018637\n",
      "The Mean Absolute Error is:  17.463968091943016 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with max_depth = 4\n",
      "\n",
      "The RVE is:  0.7313332994013582\n",
      "The rmse is:  17.716759232767046\n",
      "The Correlation Score is is: 0.8552 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  162.53771649484537\n",
      "The Mean Absolute Error is:  12.248681863956374 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with max_depth = 7\n",
      "\n",
      "The RVE is:  0.8066077210526179\n",
      "The rmse is:  15.03126644865506\n",
      "The Correlation Score is is: 0.8982 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  184.35\n",
      "The Mean Absolute Error is:  9.70794534845227 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with max_depth = 10\n",
      "\n",
      "The RVE is:  0.8462780036357106\n",
      "The rmse is:  13.401215415262667\n",
      "The Correlation Score is is: 0.9204 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  184.35\n",
      "The Mean Absolute Error is:  8.025890849388649 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with max_depth = 13\n",
      "\n",
      "The RVE is:  0.8684003412975487\n",
      "The rmse is:  12.399477161978455\n",
      "The Correlation Score is is: 0.9326 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  184.35\n",
      "The Mean Absolute Error is:  6.9568995601949934 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with max_depth = 16\n",
      "\n",
      "The RVE is:  0.8711865395135652\n",
      "The rmse is:  12.267561063721558\n",
      "The Correlation Score is is: 0.9348 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  184.35\n",
      "The Mean Absolute Error is:  6.504779186139803 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with max_depth = 19\n",
      "\n",
      "The RVE is:  0.86581758612548\n",
      "The rmse is:  12.520741078703898\n",
      "The Correlation Score is is: 0.9323 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  184.35\n",
      "The Mean Absolute Error is:  6.465182047590848 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with max_depth = 22\n",
      "\n",
      "The RVE is:  0.8670927574751923\n",
      "The rmse is:  12.461147543611672\n",
      "The Correlation Score is is: 0.9329 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  184.35\n",
      "The Mean Absolute Error is:  6.453214400379504 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with max_depth = 25\n",
      "\n",
      "The RVE is:  0.8747781729810158\n",
      "The rmse is:  12.095753025436753\n",
      "The Correlation Score is is: 0.9369 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  168.0\n",
      "The Mean Absolute Error is:  6.333937827824639 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with max_depth = 28\n",
      "\n",
      "The RVE is:  0.8701162602086987\n",
      "The rmse is:  12.318409650749675\n",
      "The Correlation Score is is: 0.9344 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  184.35\n",
      "The Mean Absolute Error is:  6.386343708218812 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#k-fold cross validation with stopping criteria max_depth \n",
    "for i in max_depth_values:\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    TRUTH=None\n",
    "    PREDS=None\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_TRAIN):\n",
    "        X_train, X_test = X_TRAIN[train_index], X_TRAIN[test_index]\n",
    "        y_train, y_test = y_TRAIN[train_index], y_TRAIN[test_index]\n",
    "        \n",
    "        model = DecisionTreeRegressor(max_depth=i,random_state=16)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "      \n",
    "        if TRUTH is None:\n",
    "            PREDS=preds\n",
    "            TRUTH=y_test\n",
    "        else:\n",
    "            PREDS=np.hstack((PREDS, preds))\n",
    "            TRUTH=np.hstack((TRUTH, y_test))\n",
    "            \n",
    "    \n",
    "    print(f\"Decision Tree Regressor with max_depth = {i}\\n\")\n",
    "    print(\"The RVE is: \", explained_variance_score(TRUTH, PREDS))\n",
    "    print(\"The rmse is: \", mean_squared_error(TRUTH, PREDS, squared=False))\n",
    "    \n",
    "    corr, pval = pearsonr(TRUTH, PREDS)\n",
    "\n",
    "    print(\"The Correlation Score is is: %6.4f (p-value=%e)\\n\"%(corr,pval))\n",
    "\n",
    "    print(\"The Maximum Error is: \", max_error(TRUTH, PREDS))\n",
    "    print(\"The Mean Absolute Error is: \", mean_absolute_error(TRUTH, PREDS),\"\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "\n",
      "The RVE is:  0.7338844880678093\n",
      "The rmse is:  17.632384786835757\n",
      "The Correlation Score is is: 0.8567 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  176.05701931798137\n",
      "The Mean Absolute Error is:  13.354145283698646 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression with k-fold cross validation \n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "TRUTH=None\n",
    "PREDS=None\n",
    "\n",
    "for train_index, test_index in kf.split(X_TRAIN):\n",
    "    X_train, X_test = X_TRAIN[train_index], X_TRAIN[test_index]\n",
    "    y_train, y_test = y_TRAIN[train_index], y_TRAIN[test_index]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    if TRUTH is None:\n",
    "        PREDS=preds\n",
    "        TRUTH=y_test\n",
    "    else:\n",
    "        PREDS=np.hstack((PREDS, preds))\n",
    "        TRUTH=np.hstack((TRUTH, y_test))\n",
    "        \n",
    "\n",
    "print(f\"Linear Regression\\n\")\n",
    "print(\"The RVE is: \", explained_variance_score(TRUTH, PREDS))\n",
    "print(\"The rmse is: \", mean_squared_error(TRUTH, PREDS, squared=False))\n",
    "\n",
    "corr, pval = pearsonr(TRUTH, PREDS)\n",
    "\n",
    "print(\"The Correlation Score is is: %6.4f (p-value=%e)\\n\"%(corr,pval))\n",
    "\n",
    "print(\"The Maximum Error is: \", max_error(TRUTH, PREDS))\n",
    "print(\"The Mean Absolute Error is: \", mean_absolute_error(TRUTH, PREDS),\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the range of values of the min_samples_leaf hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 7, 13, 19, 25, 31, 37, 43, 49, 55]\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter min_samples_leaf \n",
    "\n",
    "min_samples_leaf_values = []\n",
    "\n",
    "for i in range(1,60,6):\n",
    "    min_samples_leaf_values.append(i)\n",
    "\n",
    "print(min_samples_leaf_values)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor with hyperparameter min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor with min_samples_leaf = 1\n",
      "\n",
      "The RVE is:  0.8672337444573299\n",
      "The rmse is:  12.454364352022552\n",
      "The Correlation Score is is: 0.9330 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  184.35\n",
      "The Mean Absolute Error is:  6.440891234439516 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with min_samples_leaf = 7\n",
      "\n",
      "The RVE is:  0.8811132783425116\n",
      "The rmse is:  11.785375373457049\n",
      "The Correlation Score is is: 0.9393 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  171.27525\n",
      "The Mean Absolute Error is:  6.630999373025378 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with min_samples_leaf = 13\n",
      "\n",
      "The RVE is:  0.8734132123050791\n",
      "The rmse is:  12.161036246356895\n",
      "The Correlation Score is is: 0.9350 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  158.57692307692307\n",
      "The Mean Absolute Error is:  6.962829619176944 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with min_samples_leaf = 19\n",
      "\n",
      "The RVE is:  0.8697542290936975\n",
      "The rmse is:  12.33591397308907\n",
      "The Correlation Score is is: 0.9329 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  180.82895454545454\n",
      "The Mean Absolute Error is:  7.246447852915878 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with min_samples_leaf = 25\n",
      "\n",
      "The RVE is:  0.8687552795120574\n",
      "The rmse is:  12.382801736855669\n",
      "The Correlation Score is is: 0.9322 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  160.96906896551724\n",
      "The Mean Absolute Error is:  7.387283460453335 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with min_samples_leaf = 31\n",
      "\n",
      "The RVE is:  0.8636012702730496\n",
      "The rmse is:  12.623578135524298\n",
      "The Correlation Score is is: 0.9294 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  175.6144918032787\n",
      "The Mean Absolute Error is:  7.623170359012776 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with min_samples_leaf = 37\n",
      "\n",
      "The RVE is:  0.8578723278455505\n",
      "The rmse is:  12.885937654057242\n",
      "The Correlation Score is is: 0.9263 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  177.7301914893617\n",
      "The Mean Absolute Error is:  7.8266135251433955 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with min_samples_leaf = 43\n",
      "\n",
      "The RVE is:  0.8528380440183329\n",
      "The rmse is:  13.112154239942026\n",
      "The Correlation Score is is: 0.9236 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  166.09553571428572\n",
      "The Mean Absolute Error is:  8.025154920505623 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with min_samples_leaf = 49\n",
      "\n",
      "The RVE is:  0.8509167921581767\n",
      "The rmse is:  13.197828200234383\n",
      "The Correlation Score is is: 0.9226 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  177.25091836734694\n",
      "The Mean Absolute Error is:  8.15323587429897 \n",
      "\n",
      "\n",
      "Decision Tree Regressor with min_samples_leaf = 55\n",
      "\n",
      "The RVE is:  0.8454944075591238\n",
      "The rmse is:  13.435326629390163\n",
      "The Correlation Score is is: 0.9196 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is:  173.51667441860465\n",
      "The Mean Absolute Error is:  8.357401171737783 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#k-fold cross validation with stopping criteria min_sample_leaf \n",
    "\n",
    "for i in min_samples_leaf_values:\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    TRUTH=None\n",
    "    PREDS=None\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in kf.split(X_TRAIN):\n",
    "        X_train, X_test = X_TRAIN[train_index], X_TRAIN[test_index]\n",
    "        y_train, y_test = y_TRAIN[train_index], y_TRAIN[test_index]\n",
    "        \n",
    "        model = DecisionTreeRegressor(min_samples_leaf=i,random_state=16)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        preds_train = model.predict(X_train)\n",
    "        \n",
    "        \n",
    "        if TRUTH is None:\n",
    "            PREDS=preds\n",
    "            TRUTH=y_test\n",
    "        else:\n",
    "            PREDS=np.hstack((PREDS, preds))\n",
    "            TRUTH=np.hstack((TRUTH, y_test))\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f\"Decision Tree Regressor with min_samples_leaf = {i}\\n\")\n",
    "    print(\"The RVE is: \", explained_variance_score(TRUTH, PREDS))\n",
    "    print(\"The rmse is: \", mean_squared_error(TRUTH, PREDS, squared=False))\n",
    "    \n",
    "    corr, pval = pearsonr(TRUTH, PREDS)\n",
    "\n",
    "    print(\"The Correlation Score is is: %6.4f (p-value=%e)\\n\"%(corr,pval))\n",
    "    \n",
    "    print(\"The Maximum Error is: \", max_error(TRUTH, PREDS))\n",
    "    print(\"The Mean Absolute Error is: \", mean_absolute_error(TRUTH, PREDS),\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(min_samples_leaf=13, random_state=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(min_samples_leaf=13, random_state=16)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(min_samples_leaf=13, random_state=16)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After validating the results we achieved the best model\n",
    "best_model = DecisionTreeRegressor(min_samples_leaf = 13,random_state=16)\n",
    "best_model.fit(X_TRAIN, y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.8779682971428481\n",
      "The rmse is:  12.048725704889668\n",
      "The Correlation Score is is: 0.9372 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  109.49384615384615\n",
      "The Mean Absolute Error is:  6.773300086827552\n"
     ]
    }
   ],
   "source": [
    "# best model validation with IVS\n",
    "ivs_preds=best_model.predict(X_IVS)\n",
    "\n",
    "print(\"The RVE is: \", explained_variance_score(y_IVS, ivs_preds))\n",
    "print(\"The rmse is: \", mean_squared_error(y_IVS, ivs_preds, squared=False))\n",
    "corr, pval=pearsonr(y_IVS, ivs_preds)\n",
    "print(\"The Correlation Score is is: %6.4f (p-value=%e)\\n\"%(corr,pval))\n",
    "\n",
    "print(\"The Maximum Error is is: \", max_error(y_IVS, ivs_preds))\n",
    "print(\"The Mean Absolute Error is: \", mean_absolute_error(y_IVS, ivs_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(ivs_preds, y_IVS)\n",
    "plt.plot((0, 150), (0,150), c=\"r\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
      "0                 -2.1737           -2.5469               -1.8316   \n",
      "1                 -2.1737           -2.5469               -1.8316   \n",
      "2                 -2.1737           -2.5469               -1.8316   \n",
      "3                 -2.1737           -2.5469               -1.8316   \n",
      "4                 -2.1737           -1.5994               -0.9850   \n",
      "...                   ...               ...                   ...   \n",
      "21169             -1.4777           -1.5696               -1.3792   \n",
      "21170             -1.4777           -1.5696               -1.3794   \n",
      "21171              0.6104           -1.2091               -0.3571   \n",
      "21172             -1.4777            2.3104                3.2518   \n",
      "21173             -0.0856           -0.3717               -0.2152   \n",
      "\n",
      "       gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
      "0                -1.9110                -1.2742              -3.2043   \n",
      "1                -1.9110                -1.2742              -3.2043   \n",
      "2                -1.9110                -1.2742              -3.2043   \n",
      "3                -1.9110                -1.2742              -3.2043   \n",
      "4                -1.0041                -0.5006              -3.2043   \n",
      "...                  ...                    ...                  ...   \n",
      "21169            -1.0551                -0.8610              -1.4650   \n",
      "21170            -1.0551                -0.8612              -1.4650   \n",
      "21171            -0.8493                -0.0501               0.8948   \n",
      "21172             2.5600                 3.2684              -1.3983   \n",
      "21173            -0.3812                -0.0983               0.0880   \n",
      "\n",
      "       wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
      "0                      -2.6712            -2.1218                -1.2523   \n",
      "1                      -2.6712            -2.1218                -1.2523   \n",
      "2                      -2.6712            -2.1218                -1.2523   \n",
      "3                      -2.6712            -2.1218                -1.2523   \n",
      "4                      -2.6712            -2.1218                -1.2523   \n",
      "...                        ...                ...                    ...   \n",
      "21169                  -2.6345            -1.6094                -0.2289   \n",
      "21170                  -2.6426            -1.6094                -0.2281   \n",
      "21171                  -0.0899            -0.8092                 0.1210   \n",
      "21172                  -1.7172            -0.6162                 3.8693   \n",
      "21173                  -0.0792             0.1018                 0.0766   \n",
      "\n",
      "       std_atomic_mass  ...  gmean_Valence  wtd_gmean_Valence  \\\n",
      "0              -2.2206  ...         0.9014             0.8055   \n",
      "1              -2.2206  ...         0.9014             0.8055   \n",
      "2              -2.2206  ...         0.9014             0.8055   \n",
      "3              -2.2206  ...         0.9014             0.8055   \n",
      "4              -2.2206  ...        -1.0090            -0.8995   \n",
      "...                ...  ...            ...                ...   \n",
      "21169          -1.5220  ...         0.3895            -0.0463   \n",
      "21170          -1.5220  ...         0.3895            -0.0465   \n",
      "21171          -1.0294  ...        -0.6248            -0.8270   \n",
      "21172          -0.1679  ...         0.7801             1.2440   \n",
      "21173          -0.0305  ...        -0.8052            -0.8533   \n",
      "\n",
      "       entropy_Valence  wtd_entropy_Valence  range_Valence  wtd_range_Valence  \\\n",
      "0              -3.3123              -2.7858        -1.6406            -1.5235   \n",
      "1              -3.3123              -2.7858        -1.6406            -1.5235   \n",
      "2              -3.3123              -2.7858        -1.6406            -1.5235   \n",
      "3              -3.3123              -2.7858        -1.6406            -1.5235   \n",
      "4              -3.3123              -2.7858        -1.6406            -1.5235   \n",
      "...                ...                  ...            ...                ...   \n",
      "21169          -1.5698              -2.7590        -0.8366             1.5587   \n",
      "21170          -1.5698              -2.7649        -0.8366             1.5605   \n",
      "21171           0.5646               0.6106         0.7715            -0.4937   \n",
      "21172          -1.6243              -1.7637        -0.0325             1.9778   \n",
      "21173           0.1807               0.1790        -0.8366            -0.4916   \n",
      "\n",
      "       std_Valence  wtd_std_Valence  critical_temp  critical_temp_high  \n",
      "0          -1.7297          -1.4782         52.000                   0  \n",
      "1          -1.7297          -1.4782         50.000                   0  \n",
      "2          -1.7297          -1.4782         41.500                   0  \n",
      "3          -1.7297          -1.4782         32.000                   0  \n",
      "4          -1.7297          -1.4782         29.000                   0  \n",
      "...            ...              ...            ...                 ...  \n",
      "21169      -0.6981          -1.4088          0.596                   0  \n",
      "21170      -0.6981          -1.4181          0.700                   0  \n",
      "21171       0.7460          -0.1070         73.000                   0  \n",
      "21172       0.3334           0.2772          0.280                   0  \n",
      "21173      -0.8363          -0.9334         97.000                   1  \n",
      "\n",
      "[21174 rows x 83 columns] \n",
      "\n",
      "       number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
      "0                 -2.1737           -2.5469               -1.8316   \n",
      "1                 -2.1737           -2.5469               -1.8316   \n",
      "2                 -2.1737           -2.5469               -1.8316   \n",
      "3                 -2.1737           -2.5469               -1.8316   \n",
      "4                 -2.1737           -1.5994               -0.9850   \n",
      "...                   ...               ...                   ...   \n",
      "21169             -1.4777           -1.5696               -1.3792   \n",
      "21170             -1.4777           -1.5696               -1.3794   \n",
      "21171              0.6104           -1.2091               -0.3571   \n",
      "21172             -1.4777            2.3104                3.2518   \n",
      "21173             -0.0856           -0.3717               -0.2152   \n",
      "\n",
      "       gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
      "0                -1.9110                -1.2742              -3.2043   \n",
      "1                -1.9110                -1.2742              -3.2043   \n",
      "2                -1.9110                -1.2742              -3.2043   \n",
      "3                -1.9110                -1.2742              -3.2043   \n",
      "4                -1.0041                -0.5006              -3.2043   \n",
      "...                  ...                    ...                  ...   \n",
      "21169            -1.0551                -0.8610              -1.4650   \n",
      "21170            -1.0551                -0.8612              -1.4650   \n",
      "21171            -0.8493                -0.0501               0.8948   \n",
      "21172             2.5600                 3.2684              -1.3983   \n",
      "21173            -0.3812                -0.0983               0.0880   \n",
      "\n",
      "       wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
      "0                      -2.6712            -2.1218                -1.2523   \n",
      "1                      -2.6712            -2.1218                -1.2523   \n",
      "2                      -2.6712            -2.1218                -1.2523   \n",
      "3                      -2.6712            -2.1218                -1.2523   \n",
      "4                      -2.6712            -2.1218                -1.2523   \n",
      "...                        ...                ...                    ...   \n",
      "21169                  -2.6345            -1.6094                -0.2289   \n",
      "21170                  -2.6426            -1.6094                -0.2281   \n",
      "21171                  -0.0899            -0.8092                 0.1210   \n",
      "21172                  -1.7172            -0.6162                 3.8693   \n",
      "21173                  -0.0792             0.1018                 0.0766   \n",
      "\n",
      "       std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  \\\n",
      "0              -2.2206  ...            0.7124         0.9014   \n",
      "1              -2.2206  ...            0.7124         0.9014   \n",
      "2              -2.2206  ...            0.7124         0.9014   \n",
      "3              -2.2206  ...            0.7124         0.9014   \n",
      "4              -2.2206  ...           -0.9684        -1.0090   \n",
      "...                ...  ...               ...            ...   \n",
      "21169          -1.5220  ...           -0.1272         0.3895   \n",
      "21170          -1.5220  ...           -0.1274         0.3895   \n",
      "21171          -1.0294  ...           -0.8538        -0.6248   \n",
      "21172          -0.1679  ...            1.2167         0.7801   \n",
      "21173          -0.0305  ...           -0.9130        -0.8052   \n",
      "\n",
      "       wtd_gmean_Valence  entropy_Valence  wtd_entropy_Valence  range_Valence  \\\n",
      "0                 0.8055          -3.3123              -2.7858        -1.6406   \n",
      "1                 0.8055          -3.3123              -2.7858        -1.6406   \n",
      "2                 0.8055          -3.3123              -2.7858        -1.6406   \n",
      "3                 0.8055          -3.3123              -2.7858        -1.6406   \n",
      "4                -0.8995          -3.3123              -2.7858        -1.6406   \n",
      "...                  ...              ...                  ...            ...   \n",
      "21169            -0.0463          -1.5698              -2.7590        -0.8366   \n",
      "21170            -0.0465          -1.5698              -2.7649        -0.8366   \n",
      "21171            -0.8270           0.5646               0.6106         0.7715   \n",
      "21172             1.2440          -1.6243              -1.7637        -0.0325   \n",
      "21173            -0.8533           0.1807               0.1790        -0.8366   \n",
      "\n",
      "       wtd_range_Valence  std_Valence  wtd_std_Valence  critical_temp_high  \n",
      "0                -1.5235      -1.7297          -1.4782                   0  \n",
      "1                -1.5235      -1.7297          -1.4782                   0  \n",
      "2                -1.5235      -1.7297          -1.4782                   0  \n",
      "3                -1.5235      -1.7297          -1.4782                   0  \n",
      "4                -1.5235      -1.7297          -1.4782                   0  \n",
      "...                  ...          ...              ...                 ...  \n",
      "21169             1.5587      -0.6981          -1.4088                   0  \n",
      "21170             1.5605      -0.6981          -1.4181                   0  \n",
      "21171            -0.4937       0.7460          -0.1070                   0  \n",
      "21172             1.9778       0.3334           0.2772                   0  \n",
      "21173            -0.4916      -0.8363          -0.9334                   1  \n",
      "\n",
      "[21174 rows x 82 columns]\n",
      "Counter({0: 17625, 1: 3549})\n",
      "Positive critical_temp_high corresponds to 16.761122130915275 % of the dataset.\n",
      "\n",
      "critical_temp_high             1.000000\n",
      "wtd_std_ThermalConductivity    0.452456\n",
      "range_ThermalConductivity      0.420253\n",
      "std_ThermalConductivity        0.411498\n",
      "range_atomic_radius            0.385147\n",
      "                                 ...   \n",
      "gmean_Density                 -0.294683\n",
      "gmean_Valence                 -0.330467\n",
      "mean_Valence                  -0.351577\n",
      "wtd_gmean_Valence             -0.357518\n",
      "wtd_mean_Valence              -0.370779\n",
      "Name: critical_temp_high, Length: 82, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_t = df\n",
    "\n",
    "#adds a column to the dataframe with the value 1 when the critical_temp >= 80 and zero when its below 80\n",
    "df_t['critical_temp_high'] = (df_t['critical_temp'] >= 80.0).astype(int)\n",
    "\n",
    "print(df_t,\"\\n\")\n",
    "\n",
    "df_t = df_t.drop(\"critical_temp\",axis=1)\n",
    "\n",
    "print(df_t)\n",
    "\n",
    "# summarize critical_temp_high distribution\n",
    "counter = Counter(df_t['critical_temp_high'])\n",
    "print(counter)\n",
    "print('Positive critical_temp_high corresponds to', counter[1]/(counter[0]+counter[1])*100,'% of the dataset.\\n')\n",
    "\n",
    "\n",
    "#creates a matrix of correlations\n",
    "corr_matrix = df_t.corr() \n",
    "#how much each attribute correlates with the critical_temp target variable value, the lower the value the least relevant the feature is\n",
    "print(corr_matrix[\"critical_temp_high\"].sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21174, 81)\n",
      "(21174,)\n"
     ]
    }
   ],
   "source": [
    "#defining the X and y for the train test split\n",
    "Xt = df_t.values[:,:81]\n",
    "yt = df_t.values[:,81] #critical_temp_high is the last column\n",
    "\n",
    "print(Xt.shape)\n",
    "print(yt.shape)\n",
    "\n",
    "#Creating an independent Validation Set (IVS)\n",
    "Xt_TRAIN, Xt_IVS, yt_TRAIN, yt_IVS = train_test_split(Xt, yt, test_size=0.25, random_state=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier with hyperparameter max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier with max_depth = 1\n",
      "\n",
      "The accuracy score is:  0.8339\n",
      "The Precision is:  0.0000\n",
      "The Recall is:  0.0000\n",
      "The F1 score is:  0.0000\n",
      "The Matthews correlation coefficient is:  0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier with max_depth = 4\n",
      "\n",
      "The accuracy score is:  0.8790\n",
      "The Precision is:  0.6715\n",
      "The Recall is:  0.5315\n",
      "The F1 score is:  0.5933\n",
      "The Matthews correlation coefficient is:  0.5283\n",
      "\n",
      "Decision Tree Classifier with max_depth = 7\n",
      "\n",
      "The accuracy score is:  0.9115\n",
      "The Precision is:  0.7359\n",
      "The Recall is:  0.7290\n",
      "The F1 score is:  0.7324\n",
      "The Matthews correlation coefficient is:  0.6794\n",
      "\n",
      "Decision Tree Classifier with max_depth = 10\n",
      "\n",
      "The accuracy score is:  0.9265\n",
      "The Precision is:  0.7766\n",
      "The Recall is:  0.7828\n",
      "The F1 score is:  0.7797\n",
      "The Matthews correlation coefficient is:  0.7356\n",
      "\n",
      "Decision Tree Classifier with max_depth = 13\n",
      "\n",
      "The accuracy score is:  0.9293\n",
      "The Precision is:  0.7807\n",
      "The Recall is:  0.7991\n",
      "The F1 score is:  0.7898\n",
      "The Matthews correlation coefficient is:  0.7474\n",
      "\n",
      "Decision Tree Classifier with max_depth = 16\n",
      "\n",
      "The accuracy score is:  0.9299\n",
      "The Precision is:  0.7853\n",
      "The Recall is:  0.7957\n",
      "The F1 score is:  0.7904\n",
      "The Matthews correlation coefficient is:  0.7484\n",
      "\n",
      "Decision Tree Classifier with max_depth = 19\n",
      "\n",
      "The accuracy score is:  0.9292\n",
      "The Precision is:  0.7894\n",
      "The Recall is:  0.7828\n",
      "The F1 score is:  0.7861\n",
      "The Matthews correlation coefficient is:  0.7437\n",
      "\n",
      "Decision Tree Classifier with max_depth = 22\n",
      "\n",
      "The accuracy score is:  0.9296\n",
      "The Precision is:  0.7892\n",
      "The Recall is:  0.7862\n",
      "The F1 score is:  0.7877\n",
      "The Matthews correlation coefficient is:  0.7455\n",
      "\n",
      "Decision Tree Classifier with max_depth = 25\n",
      "\n",
      "The accuracy score is:  0.9289\n",
      "The Precision is:  0.7908\n",
      "The Recall is:  0.7779\n",
      "The F1 score is:  0.7843\n",
      "The Matthews correlation coefficient is:  0.7417\n",
      "\n",
      "Decision Tree Classifier with max_depth = 28\n",
      "\n",
      "The accuracy score is:  0.9300\n",
      "The Precision is:  0.7886\n",
      "The Recall is:  0.7904\n",
      "The F1 score is:  0.7895\n",
      "The Matthews correlation coefficient is:  0.7475\n"
     ]
    }
   ],
   "source": [
    "#k-fold cross validation with stopping criteria max_depth \n",
    "\n",
    "for i in max_depth_values:\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    TRUTH=None\n",
    "    PREDS=None\n",
    "    \n",
    "    for train_t_index, test_t_index in kf.split(Xt_TRAIN):\n",
    "        Xt_train, Xt_test = Xt_TRAIN[train_t_index], Xt_TRAIN[test_t_index]\n",
    "        yt_train, yt_test = yt_TRAIN[train_t_index], yt_TRAIN[test_t_index]\n",
    "        \n",
    "        model_t = DecisionTreeClassifier(max_depth=i,random_state=16)\n",
    "        model_t.fit(Xt_train, yt_train)\n",
    "        preds_t = model_t.predict(Xt_test)\n",
    "      \n",
    "        if TRUTH is None:\n",
    "            PREDS=preds_t\n",
    "            TRUTH=yt_test\n",
    "        else:\n",
    "            PREDS=np.hstack((PREDS, preds_t))\n",
    "            TRUTH=np.hstack((TRUTH, yt_test))\n",
    "    \n",
    "    \n",
    "    print(f\"\\nDecision Tree Classifier with max_depth = {i}\\n\")\n",
    "    print(\"The accuracy score is: %7.4f\" % accuracy_score(TRUTH, PREDS))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(TRUTH, PREDS))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(TRUTH, PREDS))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(TRUTH, PREDS))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(TRUTH, PREDS))\n",
    "    \n",
    "    '''print(\"\\nThis is the Confusion Matrix\")\n",
    "    print(f\"{pd.DataFrame(confusion_matrix(TRUTH, PREDS))}\\n\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier with hyperparameter min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Classifier with min_samples_leaf = 1\n",
      "\n",
      "The accuracy score is:  0.9266\n",
      "The Precision is:  0.7789\n",
      "The Recall is:  0.7798\n",
      "The F1 score is:  0.7793\n",
      "The Matthews correlation coefficient is:  0.7353\n",
      "\n",
      "Decision Tree Classifier with min_samples_leaf = 7\n",
      "\n",
      "The accuracy score is:  0.9278\n",
      "The Precision is:  0.7800\n",
      "The Recall is:  0.7877\n",
      "The F1 score is:  0.7839\n",
      "The Matthews correlation coefficient is:  0.7406\n",
      "\n",
      "Decision Tree Classifier with min_samples_leaf = 13\n",
      "\n",
      "The accuracy score is:  0.9244\n",
      "The Precision is:  0.7811\n",
      "The Recall is:  0.7574\n",
      "The F1 score is:  0.7691\n",
      "The Matthews correlation coefficient is:  0.7240\n",
      "\n",
      "Decision Tree Classifier with min_samples_leaf = 19\n",
      "\n",
      "The accuracy score is:  0.9201\n",
      "The Precision is:  0.7690\n",
      "The Recall is:  0.7418\n",
      "The F1 score is:  0.7552\n",
      "The Matthews correlation coefficient is:  0.7076\n",
      "\n",
      "Decision Tree Classifier with min_samples_leaf = 25\n",
      "\n",
      "The accuracy score is:  0.9180\n",
      "The Precision is:  0.7722\n",
      "The Recall is:  0.7183\n",
      "The F1 score is:  0.7443\n",
      "The Matthews correlation coefficient is:  0.6962\n",
      "\n",
      "Decision Tree Classifier with min_samples_leaf = 31\n",
      "\n",
      "The accuracy score is:  0.9166\n",
      "The Precision is:  0.7681\n",
      "The Recall is:  0.7130\n",
      "The F1 score is:  0.7395\n",
      "The Matthews correlation coefficient is:  0.6906\n",
      "\n",
      "Decision Tree Classifier with min_samples_leaf = 37\n",
      "\n",
      "The accuracy score is:  0.9167\n",
      "The Precision is:  0.7743\n",
      "The Recall is:  0.7036\n",
      "The F1 score is:  0.7372\n",
      "The Matthews correlation coefficient is:  0.6890\n",
      "\n",
      "Decision Tree Classifier with min_samples_leaf = 43\n",
      "\n",
      "The accuracy score is:  0.9135\n",
      "The Precision is:  0.7581\n",
      "The Recall is:  0.7043\n",
      "The F1 score is:  0.7302\n",
      "The Matthews correlation coefficient is:  0.6795\n",
      "\n",
      "Decision Tree Classifier with min_samples_leaf = 49\n",
      "\n",
      "The accuracy score is:  0.9125\n",
      "The Precision is:  0.7579\n",
      "The Recall is:  0.6952\n",
      "The F1 score is:  0.7252\n",
      "The Matthews correlation coefficient is:  0.6741\n",
      "\n",
      "Decision Tree Classifier with min_samples_leaf = 55\n",
      "\n",
      "The accuracy score is:  0.9141\n",
      "The Precision is:  0.7630\n",
      "The Recall is:  0.7005\n",
      "The F1 score is:  0.7304\n",
      "The Matthews correlation coefficient is:  0.6803\n"
     ]
    }
   ],
   "source": [
    "#k-fold cross validation with stopping criteria min_sample_leaf \n",
    "\n",
    "for i in min_samples_leaf_values:\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    TRUTH=None\n",
    "    PREDS=None\n",
    "    \n",
    "    for train_t_index, test_t_index in kf.split(Xt_TRAIN):\n",
    "        Xt_train, Xt_test = Xt_TRAIN[train_t_index], Xt_TRAIN[test_t_index]\n",
    "        yt_train, yt_test = yt_TRAIN[train_t_index], yt_TRAIN[test_t_index]\n",
    "        \n",
    "        model_t = DecisionTreeClassifier(min_samples_leaf=i,random_state=16)\n",
    "        model_t.fit(Xt_train, yt_train)\n",
    "        preds_t = model_t.predict(Xt_test)\n",
    "      \n",
    "        if TRUTH is None:\n",
    "            PREDS=preds_t\n",
    "            TRUTH=yt_test\n",
    "        else:\n",
    "            PREDS=np.hstack((PREDS, preds_t))\n",
    "            TRUTH=np.hstack((TRUTH, yt_test))\n",
    "    \n",
    "    \n",
    "    print(f\"\\nDecision Tree Classifier with min_samples_leaf = {i}\\n\")\n",
    "    print(\"The accuracy score is: %7.4f\" % accuracy_score(TRUTH, PREDS))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(TRUTH, PREDS))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(TRUTH, PREDS))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(TRUTH, PREDS))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(TRUTH, PREDS))\n",
    "\n",
    "    '''print(\"The Classification Report:\\n\", classification_report(TRUTH, PREDS))\n",
    "    print(\"\\nThis is the Confusion Matrix\")\n",
    "    print(f\"{pd.DataFrame(confusion_matrix(TRUTH, PREDS))}\\n\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with hyperparameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 1, 10, 100]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a smaller c implies a stronger regularization, a larger c means a weaker regularization\n",
    "C_values = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 1, 10, 100] # more lower values because we have a lot of features in this dataset, and so a stronger regularization helps prevents overfitting\n",
    "C_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression with C = 0.001\n",
      "\n",
      "The accuracy score is:  0.8618\n",
      "The Precision is:  0.7367\n",
      "The Recall is:  0.2619\n",
      "The F1 score is:  0.3865\n",
      "The Matthews correlation coefficient is:  0.3841\n",
      "\n",
      "Logistic Regression with C = 0.002\n",
      "\n",
      "The accuracy score is:  0.8642\n",
      "The Precision is:  0.7319\n",
      "The Recall is:  0.2877\n",
      "The F1 score is:  0.4131\n",
      "The Matthews correlation coefficient is:  0.4018\n",
      "\n",
      "Logistic Regression with C = 0.005\n",
      "\n",
      "The accuracy score is:  0.8705\n",
      "The Precision is:  0.7299\n",
      "The Recall is:  0.3503\n",
      "The F1 score is:  0.4734\n",
      "The Matthews correlation coefficient is:  0.4458\n",
      "\n",
      "Logistic Regression with C = 0.01\n",
      "\n",
      "The accuracy score is:  0.8731\n",
      "The Precision is:  0.7051\n",
      "The Recall is:  0.4060\n",
      "The F1 score is:  0.5153\n",
      "The Matthews correlation coefficient is:  0.4709\n",
      "\n",
      "Logistic Regression with C = 0.02\n",
      "\n",
      "The accuracy score is:  0.8751\n",
      "The Precision is:  0.6953\n",
      "The Recall is:  0.4420\n",
      "The F1 score is:  0.5404\n",
      "The Matthews correlation coefficient is:  0.4885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression with C = 0.05\n",
      "\n",
      "The accuracy score is:  0.8751\n",
      "The Precision is:  0.6655\n",
      "The Recall is:  0.4985\n",
      "The F1 score is:  0.5700\n",
      "The Matthews correlation coefficient is:  0.5058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression with C = 0.1\n",
      "\n",
      "The accuracy score is:  0.8857\n",
      "The Precision is:  0.6796\n",
      "The Recall is:  0.5902\n",
      "The F1 score is:  0.6318\n",
      "The Matthews correlation coefficient is:  0.5665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression with C = 1\n",
      "\n",
      "The accuracy score is:  0.8908\n",
      "The Precision is:  0.6899\n",
      "The Recall is:  0.6224\n",
      "The F1 score is:  0.6544\n",
      "The Matthews correlation coefficient is:  0.5909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression with C = 10\n",
      "\n",
      "The accuracy score is:  0.8927\n",
      "The Precision is:  0.6914\n",
      "The Recall is:  0.6395\n",
      "The F1 score is:  0.6644\n",
      "The Matthews correlation coefficient is:  0.6013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\guilh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression with C = 100\n",
      "\n",
      "The accuracy score is:  0.8911\n",
      "The Precision is:  0.6854\n",
      "The Recall is:  0.6368\n",
      "The F1 score is:  0.6602\n",
      "The Matthews correlation coefficient is:  0.5961\n"
     ]
    }
   ],
   "source": [
    "#k-fold cross validation with stopping criteria max_depth \n",
    "\n",
    "for i in C_values:\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    TRUTH=None\n",
    "    PREDS=None\n",
    "    \n",
    "    for train_t_index, test_t_index in kf.split(Xt_TRAIN):\n",
    "        Xt_train, Xt_test = Xt_TRAIN[train_t_index], Xt_TRAIN[test_t_index]\n",
    "        yt_train, yt_test = yt_TRAIN[train_t_index], yt_TRAIN[test_t_index]\n",
    "        \n",
    "        model_t = LogisticRegression(C = i,random_state=16)\n",
    "        model_t.fit(Xt_train, yt_train)\n",
    "        preds_t = model_t.predict(Xt_test)\n",
    "      \n",
    "        if TRUTH is None:\n",
    "            PREDS=preds_t\n",
    "            TRUTH=yt_test\n",
    "        else:\n",
    "            PREDS=np.hstack((PREDS, preds_t))\n",
    "            TRUTH=np.hstack((TRUTH, yt_test))\n",
    "    \n",
    "    \n",
    "    print(f\"\\nLogistic Regression with C = {i}\\n\")\n",
    "    print(\"The accuracy score is: %7.4f\" % accuracy_score(TRUTH, PREDS))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(TRUTH, PREDS))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(TRUTH, PREDS))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(TRUTH, PREDS))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(TRUTH, PREDS))\n",
    "    \n",
    "    '''print(\"\\nThis is the Confusion Matrix\")\n",
    "    print(f\"{pd.DataFrame(confusion_matrix(TRUTH, PREDS))}\\n\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Classification model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=13, random_state=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=13, random_state=16)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=13, random_state=16)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After validating the results we achieved the best model\n",
    "best_model_t = DecisionTreeClassifier(max_depth = 13,random_state=16)\n",
    "best_model_t.fit(Xt_TRAIN, yt_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is:  0.9350\n",
      "The Precision is:  0.8277\n",
      "The Recall is:  0.7859\n",
      "The F1 score is:  0.8063\n",
      "The Matthews correlation coefficient is:  0.7677\n"
     ]
    }
   ],
   "source": [
    "ivs_t_preds =best_model_t.predict(Xt_IVS)\n",
    "\n",
    "print(\"The accuracy score is: %7.4f\" % accuracy_score(yt_IVS, ivs_t_preds))\n",
    "print(\"The Precision is: %7.4f\" % precision_score(yt_IVS, ivs_t_preds))\n",
    "print(\"The Recall is: %7.4f\" % recall_score(yt_IVS, ivs_t_preds))\n",
    "print(\"The F1 score is: %7.4f\" % f1_score(yt_IVS, ivs_t_preds))\n",
    "print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(yt_IVS, ivs_t_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
